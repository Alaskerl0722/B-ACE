Metadata-Version: 2.1
Name: rllib-qmix
Version: 0.1.0
Author: Anyscale Inc.
Requires-Python: <3.11,>=3.7
Description-Content-Type: text/markdown
Requires-Dist: gymnasium==0.26.3
Requires-Dist: ray[rllib]==2.5.1
Provides-Extra: development
Requires-Dist: pytest>=7.2.2; extra == "development"
Requires-Dist: pre-commit==2.21.0; extra == "development"
Requires-Dist: torch==1.12.0; extra == "development"
Requires-Dist: tensorflow==2.11.0; extra == "development"
Requires-Dist: tensorflow-probability==0.19.0; extra == "development"

# QMIX (Monotonic Value Function Factorisation for Multi-Agent RL)

[QMIX](https://arxiv.org/abs/1803.11485) Q-Mix is a specialized multi-agent algorithm. Code here is adapted from https://github.com/oxwhirl/pymarl_alpha to integrate with RLlib multi-agent APIs. To use Q-Mix, you must specify an agent grouping in the environment (see the two-step game example). Currently, all agents in the group must be homogeneous. The algorithm can be scaled by increasing the number of workers or using Ape-X.


## Installation

```
conda create -n rllib-qmix python=3.10
conda activate rllib-qmix
pip install -r requirements.txt
pip install -e '.[development]'
```

## Usage

[QMIX Example]()
